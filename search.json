[{"title":"hexo 配置标签","url":"/jingjie.github.io/2019/12/05/hexo-配置标签/","content":"\n## 配置步骤\n\n#### 1、[创建文章命令](https://hexo.io/zh-cn/docs/commands)\n\n命令格式\n\n>hexo new [layout] <title>\n\n新建一篇文章。如果没有设置 layout 的话，默认使用 _config.yml 中的 default_layout 参数代替。如果标题包含空格的话，请使用引号括起来。\n\n#### 2、[hexo 配置文件 _config.yml 标签配置](https://hexo.io/zh-cn/docs/configuration)\n\n```\n...\n# Directory\nsource_dir: source\npublic_dir: public\ntag_dir: tags # 标签目录，在 source 目录下\narchive_dir: archives\ncategory_dir: categories\ncode_dir: downloads/code\ni18n_dir: :lang\nskip_render:\n...\n```\n\n#### 3、主题配置文件 _config.yml 标签配置\n\n是在 themes 目录下的主题配置文件\n\n```\n...\nmenu:\n  categories: /categories\n  tags: /tags # 标签\n  archives: /archives\n  about: /about\n...\n```\n\n\n#### 4、[scaffolds（模板）配置标签变量](https://hexo.io/zh-cn/docs/writing#模版（Scaffold）)\n\n在新建文章时，Hexo 会根据 scaffolds 文件夹内相对应的文件来建立文件，例如：\n\n>hexo new post \"My Gallery\"\n\n在执行这行指令时，Hexo 会尝试在 scaffolds 文件夹中寻找 post.md，并根据其内容建立文章，以下是您可以在模版中使用的变量：\n\n变量 | 描述\n-----|-----\nlayout | 布局\ntitle | 标题\ndate | 文件建立日期\ntags | 标签\ncategories | 分类\n... | ...\n\n## 给文章添加标签\n\n通过 `hexo new \"文章名称\"` 创建好文章后，添加标签，如：\n\n```\n---\ntitle: hexo 配置标签\ndate: 2019-12-05 11:58:24\ntags:\n- MySQL # 标签名称1\n- 数据库 # 标签名称2\n---\n\n# 以下文章内容 略\n...\n```\n\n**注意:** 在文章顶部要空一行，不然标签不会生效","tags":["其它"]},{"title":"使用 acme.sh 安装 Let’ s Encrypt 提供的免费 SSL 证书","url":"/jingjie.github.io/2019/12/05/使用 acme.sh 安装 Let’ s Encrypt 提供的免费 SSL 证书/","content":"# 方式一\n----\n\n### 测试环境 \n\nUbuntu 18.04\n\nNginx\n\n----\n\n### 准备\n\n+ 开放云服务器 443 端口\n+ 开放系统 443 端口\n\nNote：https 成功后，记得把网站所有连接换成 https\n\n----\n\n### 1. 介绍\n\nLet’ s Encrypt已有免费的证书可用，以后的网站估计都要上https的吧，所以把我的网站上的证书换了一下，这节主要是参考使用 acme.sh 给 Nginx 安装 Let’ s Encrypt 提供的免费 SSL 证书这篇文章，并结合自己的情况，把我的经验记录下来。\n\n### 2. 安装\n\n我们使用acme.sh来申请和管理证书，它很简单用，还能够利用crontab自动更新证书，而且是默认就有的功能。\n\n首先安装：\n\n```shell\n1、cd\n2、wget -O -  https://get.acme.sh | sh\n3、cd .acme.sh\n```\n\n安装完之后，可以退出登录，再重新登录，或者执行一下**『source ~/.bashrc』**。\n\n之后就可以使用 **acme.sh** 命令了。\n\n### 3. 申请证书\n\n首先申请和下载证书：\n\n```shell\n# -w 后面写上你自己的网站根目录 -d 自己的网站域名\n./acme.sh --issue -d www.nicefutureworld.com -w /home/wwwroot/www.nicefutureworld.com/current/public\n```\n\n申请成功后，证书会被保存在 .acme.sh 目录里面的 www.nicefutureworld.com  目录里面：\n\n![fc61f2da01de2d5389a4e5e0f6e9119.png](https://www.nicefutureworld.com/storage/article/2019/07/25/5gbruO0pn4Ln71CQSGj3q9UWbs7lEXRNv5mMg4Vh.png)\n\n接下来我们要把证书安装到你的应用中：\n\n```shell\n# ssl 文件夹不存在则先创建，需要有写的权限\n./acme.sh --installcert -d boat.rails365.net \\\n               --keypath       /home/wwwroot/www.nicefutureworld.com/ssl/www.nicefutureworld.com.key  \\\n               --fullchainpath /home/wwwroot/www.nicefutureworld.com/ssl/www.nicefutureworld.com.key.pem \\\n               --reloadcmd     \"sudo lnmp reload\"\n```\n\n接下来，还需要再生成一个文件，很多ssl的配置都需要它：\n\n```\nopenssl dhparam -out /home/wwwroot/www.nicefutureworld.com/ssl/dhparam.pem 2048\n```\n\n### 4. nginx配置\n\n```\nupstream boat_manager {\n\tserver unix:///home/wwwroot/www.nicefutureworld.com/shared/tmp/sockets/puma.sock fail_timeout=0;\n}\n\nserver {\n\tlisten 443 ssl;\n\tserver_name www.nicefutureworld.com;\n\tssl_certificate         /home/wwwroot/www.nicefutureworld.com/ssl/www.nicefutureworld.com.key.pem;\n\tssl_certificate_key     /home/wwwroot/www.nicefutureworld.com/ssl/www.nicefutureworld.com.key;\n\t# ssl_dhparam \n\tssl_dhparam             /home/wwwroot/www.nicefutureworld.com/ssl/dhparam.pem;\n\troot /home/wwwroot/www.nicefutureworld.com/current/public\n\tkeepalive_timeout 70;\n\t# 其它配置保持不变\n}\n\nserver {\n    listen 80;\n    server_name www.nicefutureworld.com;\n    return 301 https://www.nicefutureworld.com$request_uri;\n}\n```\n\n顶层的http指令那里，也需要加上这两行：\n\n```\nhttp {\n    ssl_protocols TLSv1 TLSv1.1 TLSv1.2;\n    ssl_prefer_server_ciphers on;\n}\n```\n\n原文地址：[https://www.qiuzhi99.com/articles/shi-yong-acme-sh-an-zhuang-let-s-encrypt-ti-gong-mian-fei-ssl-zheng-shu](https://www.qiuzhi99.com/articles/shi-yong-acme-sh-an-zhuang-let-s-encrypt-ti-gong-mian-fei-ssl-zheng-shu)\n\n\n# 方式二\n\n准备：\n\n>先停止 Nginx\n\n使用：https://certbot.eff.org\n\n选择自己的环境与系统：如 Nginx Ubuntu18.04\n\n![ab86c122dfd676d9b6756551565213f.png](https://www.nicefutureworld.com/storage/article/2019/07/25/C1kZHFtlEJ2AVSpUu8jZQlqZAjxNBJl2DZyz7KNu.png)\n\n接下来就是按文档步骤操作：操作完以后把 Nginx 配置跟上一样\n\n![e4bad6e0104596364783869c266cebb.png](https://www.nicefutureworld.com/storage/article/2019/07/25/TT9wnAovZTQ0zMhUMxQQCFlnWUjM3ksb36eC7giu.png)\n\n![c4f9fe7af9bda18f4fa28453ee554fa.png](https://www.nicefutureworld.com/storage/article/2019/07/25/5Bc64yUdqCG0XyzFTENee7x9sTzsSpshOEhC5xAB.png)\n\n![e835c2150102fdeefeaf207bf03bb5c.png](https://www.nicefutureworld.com/storage/article/2019/07/25/qNv7XHvzONrAWSat9yA7JUvG8yoHhLUvCVWFFk4V.png)","tags":["Linux"]},{"title":"超大表分页优化","url":"/jingjie.github.io/2019/12/05/超大表分页优化/","content":"### 一、数据库层 SQL 优化\n\n1、使用 where \n\n>每次查询时带上上一页的最大 ID  \n> select * from users where id>10000 limit 10\n\n2、利用子查询优化超大表分页\n\n> 比如：SELECT a.* FROM 表 1 a, (select id from 表 1 where 条件 LIMIT 100000,20 ) b where a.id=b.id ，先快速定位需要获取的 id 段，然后再关联查询。MySQL 并不是跳过 offset 行，而是取 offset+N 行，然后返回放弃前 offset 行，返回 N 行，那当 offset 特别大的时候，效率就非常的低下，要么控制返回的总页数，要么对超过特定阈值的页数进行 SQL 改写，利用子查询先快速定位需要获取的 id 段，然后再关联查询，就是对分页进行 SQL 改写的具体实现；  \n> 例：  \n>SQL_1： SELECT a.* FROM users a, (select id from users WHERE 条件 LIMIT 1000000,20 ) b where a.id=b.id  \n>SQL_2： SELECT id from users WHERE 条件 LIMIT 1000000,20  \n>SQL_1 性能可达 SQL_2 的 1.5 倍\n\n### 二、程序层面优化\n\n>利用缓存把查询的结果缓存起来，这样再下一次查询的时候性能就非常高。","tags":["MySQL"]},{"title":"服务器被劫持对外攻击","url":"/jingjie.github.io/2019/12/05/服务器被劫持对外攻击/","content":"/var/log/autl.log（登录日志）\n\n![7eeaeb61f6cb8e25b03ed30accd2708.png](https://www.nicefutureworld.com/storage/article/2019/09/21/3G3eDK0yXiJYbaNUBGBbWYGOzevcgkBAS91ODpC2.png)\n\nnetstat -anpt（劫持服务器攻击的 IP）\n\n![3d085b922e3a0dcf88223177e31d1ec.png](https://www.nicefutureworld.com/storage/article/2019/09/21/ZdAfLqOI8LHgM09sl8C16Uiof6Xclz6bhXw0GmqL.png)\n\n解决方案\n\n> 马上把加强各密码\n\n> 限制 ssh 错误连接次数（最后考虑后还是把这个限制去掉了）","tags":["Linux"]},{"title":"抽 象","url":"/jingjie.github.io/2019/12/05/抽 象/","content":"# 抽象\n\n个人建议看百度百科更好，理由：\n\n- 相对维基百科百度百科对抽象的描述是高层抽象，维基是低层抽象。\n\n## 个人对抽象的理解\n\n分类、找规律、找关系的过程即是抽象过程，分类、找规律、找关系的结果即抽象的结果\n\n## 抽象的应用\n\n>人们之所以需要应用抽象法，**其客观的依据就在于自然界现象的『复杂性』和事物规律的『隐蔽性』**。假如说自然界的现象十分单纯，事物的规律是一目了然的，那倒是不必要应用抽象法，不仅抽象法成为不必要，就是整个科学也是多余的了。但是，实际情祝并非如此。科学的任务就在于透过错综复杂的现象，排除假象的迷雾，揭开大自然的奥秘，科学地解释各种事实。为此就需要撇开和排除那些偶然的因素，把普遍的联系抽取出来。这就是抽象的过程。不管是什么样的规律，什么样的因果联系，人们要发现它们，总是需要应用抽象法的。抽象法也同其他的各种科学思维的方法一样，对于科 学发现来说，起着一种助发现的作用。\n\n## 抽象分类\n\n#### 表征性抽象（低层抽象）\n\n百度百科原文：\n\n>所谓表征性抽象是以可观察的事物现象为直接起点的一种初始抽象，它是对物体所表现出来的特征的抽象。例如，物体的“形状”、“重量”、“颜色”、“温度”、“波长”等等，这些关于物体的物理性质的抽象，所概括的就是物体的一些表面特征。这种抽象就属于表征性的抽象。\n\n个人理解\n\n>是人对物体通过直观性来抽象的，同一种类或物体表现出的相同特征所做出的抽象，我把它叫做单类抽象。\n\n#### 原理性抽象（高层抽象）\n\n百度百科原文：\n\n>所谓原理性抽象，是在表征性抽象基础上形成的一种深层抽象，它所把握的是事物的 **因果性** 和 **规律性** 的联系。这种抽象的成果就是定律、原理。例如，杠杆原理、落体定律、牛顿的运动定律和万有引力定律，光的反射和折射定律、化学元素周期律、生物体遗传因子的分离定律、能的转化和守恒定律、爱因斯坦的相对性运动原理等等，都属于这种原理性抽象。\n\n个人理解\n\n>具有普遍性原理、非直观的、非常隐蔽的。如万有引力，它是对所有种类都管用，是一个跨种类的抽象，我把它叫做跨类抽象\n\n\n## 科学抽象的原则\n\n上面我们一般地考察了科学抽象的类型问题，那么，怎样才能合理地、有效地进行科学抽象呢?科学抽象应当注意以下的原则：\n\n#### 必须是普遍性的东西\n\n百度百科原文：\n\n>个别的、表面的东西是偶然的东西，要进行抽象，当然不能完全脱离这些个别的、表面的、偶然的东西，但是抽象的目的并不是去抽取那些个别的、偶然的东西，抽象的目的是在于从个别的经验事实中抽出普遍性的东西，只有这样才有意义，才能进一步去认识事物的规律性。当然，**普遍性不一定是规律性，但是不普遍的东西不可能是规律性的东西**。所以，什么东西需要抽象，什么东西不需要抽象，从定性的观点来看，应当抽象出普遍性的东西。比如从对空气的观察和实验的一系列事实中，抽象地认识存在于体积、温度以及压力之间的普遍关系，并进行定量的描述，这样也就发现了气体定律。\n\n#### 高层抽象的要求\n\n百度百科原文：\n\n>　自然界事物及其规律是多层次的系统，与此相应，科学抽象也是一个多层次的系统。在科学抽象的不同层次中，有低层的抽象，也有高层的抽象。在科学发现中，相对于解释性的理论原理来说，描述性的经验定律可以说是低层抽象，而解释性的理论原理就可以说是高层抽象。\n>\n>　必须指出，我们把科学抽象区分为低层抽象和高层抽象，是相对而言的。理论抽象本身也是多层次的。比如说，**牛顿的运动定律和万有引力定律相对于开普勒的行星运动三大定律来说，是高层抽象**，因为我们通过牛顿三大运动定律和万有引力定律的结合，就能从理论上推导出开普勒由观测总结得到的行星运动三大定律。\n>\n>　**如果高层抽象不能演绎出低层抽象，那就表明这种抽象并未真正发现了更普遍的定律和原理。一切普遍性较高的定律和原理，都能演绎出普遍性较低的定律和原理。一切低层的定律和原理都是高层的定律和原理的特例。如果一个研究者从事更高层的抽象，其结果无法演绎出低层抽象，那就意味着他所作的高层抽象是无效的，不合理的，应予纠正**。\n\n#### 思维抽象\n\n百度百科原文：\n\n>　抽象思维法是指在感性认识基础上运用概念、判断、推理等方式透过现象，抽取研究对象本质的理性思维法。具体地说，科学抽象就是人们在实践的基础上，对于丰富的感性材料通过“去粗取精、去伪存真、由此及彼、由表及里”的加工制作，形成概念、判断、推理等思维形式，以反映事物的本质和规律。\n>\n>　科学抽象是由三个阶段和两次飞跃构成的辩证思维过程。第一个阶段是感性的具体，即通过感官把事物的信息在大脑中形成表象。第二阶段是从感性到抽象的规定，也是第一次飞跃。这个阶段是将事物的表象进行分解、加工、分析和研究，最终形成反映事物不同侧面的各种本质属性。第三阶段是从抽象的规定上升到思维的具体，这是科学抽象的第二次飞跃。它是将事物的各种抽象规定在思维中加以综合、完整地重现出来，形成对事物内在本质的综合性的认识。\n\n#### 抽象解读\n\n百度百科原文：\n\n>　抽象就是将人们对世界万物的感觉，用特定的图像符号表达出来。因此要理解抽象的东西，就必需从内心感受它们。举例来说，“红色“这个词语本身，在你没有建立世间存在”色彩“这种概念以前，就是一个很抽象的东西，当我们第一次接触”红色“这个词语时，并不清楚，”红色“所表达是物体的”形状“，”大小“，”质地“，还是”颜色“，这是通过我们在生活中不断的从周围的环境中慢慢感知出来的。\n>\n>　简单来说，抽象就是将内心的感受使用一种特定的符号表示出来的”过程“。知道了什么是抽象后，那么”抽象画“就很好理解了，抽象画就是画家将自己的内心感觉通过特定的颜色和形状表现出来。这些”颜色“和”形状“，并不代表任何的某体事物，只是因为我们看到了这些”颜色“和”形状“，就是自然的激发内心的一种”美好的“或”忧伤的“以及某他的各种情绪感觉。","tags":["思想","编程思维"]},{"title":"指定 IP 可访问 Elasticsearch","url":"/jingjie.github.io/2019/12/05/指定 IP 可访问 Elasticsearch/","content":"环境\n\n+ ubuntu18.04\n+ elasticsearch7.4\n+ 开放服务器对应 es 端口（主机端口+云安全组端口）\n\n编辑 elasticsearch.yml 配置文件\n```\n# Set the bind address to a specific IP (IPv4 or IPv6):\n#\n#network.host: 192.168.0.1\n# 1、指定自己的 IP 地址（内网或外网）\nnetwork.host: 0.0.0.0\n\n# 2、设置节点名称\nnode.name: node-1\n\n# 3、设置初始主节点\ncluster.initial_master_nodes: [\"node-1\"]\n\n# 4、设置跨域\nhttp.cors.enabled: true\nhttp.cors.allow-origin: \"*\"\n```\n\n\n[参考文章](https://blog.csdn.net/lidew521/article/details/88091539)","tags":["Elasticsearch"]},{"title":"字段类型及属性","url":"/jingjie.github.io/2019/12/05/字段类型及属性/","content":"版本：>= 7.0\n\n## 1、基本类型\n\n### 1-1、字符串类型\n\n#### 1-1-1、text [详情](https://www.elastic.co/guide/en/elasticsearch/reference/current/text.html#text-params)\n\n> 1、支持分词、全文检索、模糊、精确... 等查询，**不建议使用 text 聚合、排序**\n\n> 2、text 类型的最大支持长度无限制，适合大字段储存\n\n> 3、es 默认分词为 standard 分词器对文本进行分词索引\n\n#####  可选参数\n\nanalyzer\n\n>分析器，它应该用于分析的字符串字段，无论是在索引时还是在搜索时(除非被search_analyzer覆盖)。默认索引分析器或标准分析器。\n\nboost\n\n>增加权重，默认为 1.0，当搜索时指定 boost 权重，boost 越大结果越靠前\n\neager_global_ordinals\n\n>全局序号加载，经常用于聚合的字段，启用些功能一个不错的主意。es 不知道 哪些 fields 将 用于/不用于 term aggregation，因此 全局序数 在需要时才加载进内存，但，可以在mapping type上，定义 eager_global_ordinals==true，这样，refresh 时就会加载 全局序数\n\nfielddata\n\n>字段可以使用内存中的 fielddata 进行排序、聚合或脚本编制吗? 接受真或假(默认)。如果要对分词的 field 执行聚合操作，必须将fielddata设置为true，默认 false，加载FieldData是开销很大的操作，一旦它被加载后，就会在整个段的生命周期中保留在内存中\n\nfielddata_frequency_filter [详情](https://www.elastic.co/guide/en/elasticsearch/reference/current/fielddata.html#field-data-filtering)\n\n>允许决定在启用 fielddata 时在内存中加载哪些值的专项设置。默认情况下，加载所有值。\n\nfields [详情](https://www.elastic.co/guide/en/elasticsearch/reference/current/multi-fields.html)\n\n>多字段，允许为不同的目的以多种方式索引相同的字符串值，例如一个字段用于搜索，一个多字段用于排序和聚合，或者由不同的分析程序分析相同的字符串值。\n\nindex\n\n>字段是否可以被索引，默认 true\n\nindex_options\n\n>- 四种不同级别的 index options 配置，可以控制倒排索引记录的内容\n     - docs -- 记录 doc id（只索引文档编号）\n     - freqs -- 记录 doc id 和 term frequencies （索引文档编号和词频率）\n     - positions -- 记录 doc id / term position（位置） / term frequencies（词频）\n     - offsets -- 记录 doc id / term frequencies / term position / character offsets（偏移量） （索引文档编号，词频率，词偏移量（开始和结束位置）和词位置（序号））\n - text 类型默认记录 positions，其它默认 docs\n - 记录内容越多，占用储存越大\n\nindex_prefixes\n\n>如果启用，2到5个字符之间的术语前缀将被索引到一个单独的字段中。\n 这使得前缀搜索能够以更大的索引为代价更有效地运行。\n\nindex_phrases\n\n>\n\nnorms\n\n>在对查询进行评分时是否应该考虑字段长度。\n 接受真(默认)或假。\n\nsearch_analyzer\n\n>在分析字段的搜索时使用的分析器。\n 默认为分析器设置。\n\nsearch_quote_analyzer\n\n>当遇到短语时，应该在搜索时使用的分析器。\n 默认设置为search_analyzer。\n\nsimilarity\n\n>应该使用哪种评分算法或相似度。\n 默认为BM25。\n\nterm_vector\n\n>是否应该存储分析字段的项向量。\n 默认为没有。\n\n#### 1-1-2、[keyword](https://www.elastic.co/guide/en/elasticsearch/reference/current/keyword.html)\n\n> 1、不进行分词，直接索引，支持模糊、精确、聚合、排序等\n\n> 2、支持的最大长度为 32766 个 UTF-8 字符，可以通过 ignore_above 指定长度，超过部分无法被索引（类型 MySQL 的前缀索引）\n\n##### 支持参数\n\n参数名称 | 默认值 | 详情连接\n--------|-------|--------\nboost | (float) 1.0 | [boost](https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-boost.html)(默认 1.0)\neager_global_ordinals | (bool) false | [eager_global_ordinals](https://www.elastic.co/guide/en/elasticsearch/reference/current/eager-global-ordinals.html)(默认 false)\nfields |  | [fields](https://www.elastic.co/guide/en/elasticsearch/reference/current/multi-fields.html)\nignore_above | (int) 2147483647 | [ignore_above](https://www.elastic.co/guide/en/elasticsearch/reference/current/ignore-above.html)(默认值为 2147483647)\nindex | (bool) true | [index](https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-index.html)(默认 true)\nindex_options | (docs/freqs/positions/offsets) docs | [index_options](https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-index.html)(默认 docs)\nnorms | (bool) false | [norms](https://www.elastic.co/guide/en/elasticsearch/reference/current/norms.html)(默认 false)\nnull_value | null | [null_value](https://www.elastic.co/guide/en/elasticsearch/reference/current/null-value.html)(默认关闭)\nstore | (bool) false | [store](https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-store.html)(默认 false)\nsimilarity | BM25 | [similarity](https://www.elastic.co/guide/en/elasticsearch/reference/current/similarity.html)(默认 BM25)\nnormalizer | null | [normalizer](https://www.elastic.co/guide/en/elasticsearch/reference/current/similarity.html)(默认 null)\n\n### 1-2、 数字 ([Numeric](https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-types.html))\n\n> long, integer, short, byte, double, float, half_float, scaled_float\n\ntype 值 | 描述\n--------|-----\nlong | 8 字节，一个有符号的64位整数，最小值-2^63，最大值2^63-1。\ninteger | 4 字节，一个有符号的32位整数，最小值为-2^31，最大值为2^31-1。\nshort | 一个有符号的16位整数，最小值为-32,768，最大值为32,767。\nbyte | 一个有符号的8位整数，最小值为-128，最大值为127。\ndouble | 双精度64位IEEE 754浮点数，限制为有限值。\nfloat | 一种32位的单精度IEEE 754浮点数，限制为有限值。\nhalf_float | 半精度的16位IEEE 754浮点数，限制为有限值。\nscaled_float | 一个浮点数，由一个固定的双标度因子支持。scaling_factor = 100\n\n#### 支持的参数\n\n参数名称 | 默认值 | 详情连接\n--------|-------|---------\ncoerce | (bool) true | [coerce](https://www.elastic.co/guide/en/elasticsearch/reference/current/coerce.html)\nboost | (int/float) 1.0 | [boost](https://www.elastic.co/guide/en/elasticsearch/reference/current/boost.html)\ndoc_values | (bool) true | [doc_values](https://www.elastic.co/guide/en/elasticsearch/reference/current/doc_values.html)\nignore_malformed | (bool) false | [ignore_malformed](https://www.elastic.co/guide/en/elasticsearch/reference/current/ignore-malformed.html)\nindex | (bool) true | [index](https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html)\nnull_value | null | [null_value](https://www.elastic.co/guide/en/elasticsearch/reference/current/null_value.html)\nstore | (bool) false | [store](https://www.elastic.co/guide/en/elasticsearch/reference/current/store.html)\nscaled_float | 接收一个附加参数 scaling_factor | [scaled_float](https://www.elastic.co/guide/en/elasticsearch/reference/current/number.html)\nscaling_factor | (int) | [scaling_factor](https://www.elastic.co/guide/en/elasticsearch/reference/current/number.html)\n\n### 1-3、日期 ([date](https://www.elastic.co/guide/en/elasticsearch/reference/current/date.html))\n\n>1、JSON没有日期数据类型，所以Elasticsearch中的日期可以是: 包含格式化日期的字符串，例如“2015-01-01”或“2015/01/01 12:10:30”。\n\n>2、排序默认使用毫秒为单位\n\n#### 支持的参数\n\n参数名称 | 默认值 | 详情连接\n--------|-------|---------\nboost | (int/float) 1.0 | [boost](https://www.elastic.co/guide/en/elasticsearch/reference/current/boost.html)\ndoc_values | (bool) true | [doc_values](https://www.elastic.co/guide/en/elasticsearch/reference/current/doc_values.html)\nformat | (string) strict_date_optional_time、epoch_millis | [doc_values](https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-date-format.html)\nlocale | 根据环境语言 |\nignore_malformed | (bool) false | [ignore_malformed](https://www.elastic.co/guide/en/elasticsearch/reference/current/ignore-malformed.html)\nindex | (bool) true | [index](https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html)\nnull_value | null | [null_value](https://www.elastic.co/guide/en/elasticsearch/reference/current/null_value.html)\nstore | (bool) false | [store](https://www.elastic.co/guide/en/elasticsearch/reference/current/store.html)\n\n### 1-3、日期纳秒 ([date_nanos](https://www.elastic.co/guide/en/elasticsearch/reference/current/date_nanos.html))\n\n>1、此数据类型是对日期数据类型的补充。然而，两者之间有一个重要的区别。现有的日期数据类型以毫秒分辨率存储日期。date_nanos数据类型以毫微秒的分辨率存储日期，这限制了它的日期范围(大约从1970年到2262年)，因为自epoch以来，日期仍然以长毫微秒的形式存储\n\n>2、您还可以指定由||分隔的多个日期格式。可以使用与date字段相同的映射参数。\n\n>3、即使在使用date_nanos字段时，聚合的分辨率仍然是毫秒级的。\n\n### 1-4、布尔 ([boolean](https://www.elastic.co/guide/en/elasticsearch/reference/current/boolean.html))\n\n> 布尔字段接受JSON真值和假值，但也可以接受解释为真或假的字符串:\n\n#### 支持的参数\n\n参数名称 | 默认值 | 详情连接\n--------|-------|---------\nboost | (int/float) 1.0 | [boost](https://www.elastic.co/guide/en/elasticsearch/reference/current/boost.html)\ndoc_values | (bool) true | [doc_values](https://www.elastic.co/guide/en/elasticsearch/reference/current/doc_values.html)\nindex | (bool) true | [index](https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html)\nnull_value | null | [null_value](https://www.elastic.co/guide/en/elasticsearch/reference/current/null_value.html)\nstore | (bool) false | [store](https://www.elastic.co/guide/en/elasticsearch/reference/current/store.html)\n\n### 1-5、二进制 ([binary](https://www.elastic.co/guide/en/elasticsearch/reference/current/binary.html))\n\n> 二进制类型接受二进制值作为Base64编码的字符串。\n  该字段默认不存储，也不能搜索:\n\n参数名称 | 默认值 | 详情连接\n--------|-------|---------\ndoc_values | (bool) false | [doc_values](https://www.elastic.co/guide/en/elasticsearch/reference/current/doc_values.html)\nstore | (bool) false | [store](https://www.elastic.co/guide/en/elasticsearch/reference/current/store.html)\n\n### 1-6、范围 ([range](https://www.elastic.co/guide/en/elasticsearch/reference/current/range.html))\n\nTYPE | 描述\n----|----\ninteger_range | 一组32位有符号整数，最小值为-2^31，最大值为2^31-1。\nfloat_range | 单精度32位IEEE 754浮点值的范围。\nlong_range | 一组有符号的64位整数，最小值为-2^63，最大值为2^63-1。\ndouble_range | A range of double-precision 64-bit IEEE 754 floating point values.\ndate_range | 以无符号64位整数形式表示的自系统历元以来经过的日期值范围。\nip_range | 支持IPv4或IPv6(或混合)地址的ip值范围。\n\n#### 支持的参数\n\n参数名称 | 默认值 | 详情连接\n--------|-------|---------\ncoerce | (bool) true | [coerce](https://www.elastic.co/guide/en/elasticsearch/reference/current/coerce.html)\nboost | (int/float) 1.0 | [boost](https://www.elastic.co/guide/en/elasticsearch/reference/current/boost.html)\nindex | (bool) true | [index](https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html)\nstore | (bool) false | [store](https://www.elastic.co/guide/en/elasticsearch/reference/current/store.html)\n\n## 2、复杂类型\n\n### 2-1、对象 ([object](https://www.elastic.co/guide/en/elasticsearch/reference/current/object.html))\n\n>1、内部字段可以在查询、聚合等中引用，使用点符号: root.desk\n\n>2、如果需要索引对象数组而不是单个对象，请首先读取嵌套对象（nested）。\n\n>3、对象，用于单个JSON对象\n\n#### 支持的参数\n\n参数名称 | 默认值 | 描述 | 详情连接\n--------|-------|-----|----\n dynamic | (true/false/strict) true | 是否将新字段动态添加到表中 <br> 1、true 允许动态添加到表中，并且添加索引 <br> 2、false 允许动态添加到表中，不添加索引 <br> 3、strict 禁止动态添加字段 | [dynamic](https://www.elastic.co/guide/en/elasticsearch/reference/current/coerce.html))\n enabled | (bool) true | 对象字段的 JSON 值是被解析和索引还是被忽略 | [enabled](https://www.elastic.co/guide/en/elasticsearch/reference/current/enabled.html)\n properties |  | 对象中的字段，可以是任何数据类型，包括对象。可以向现有对象添加新属性。| [properties]([enabled](https://www.elastic.co/guide/en/elasticsearch/reference/current/properties.html))\n\n### 2-2、嵌套对象 ([nested](https://www.elastic.co/guide/en/elasticsearch/reference/current/nested.html))\n\n>1、嵌套的JSON对象数组\n\n 参数名称 | 默认值 | 描述 | 详情连接\n --------|-------|-----|----\n dynamic | (true/false/strict) true | 是否将新字段动态添加到表中 <br> 1、true 允许动态添加到表中，并且添加索引 <br> 2、false 允许动态添加到表中，不添加索引 <br> 3、strict 禁止动态添加字段 | [dynamic](https://www.elastic.co/guide/en/elasticsearch/reference/current/coerce.html))\n properties |  | 对象中的字段，可以是任何数据类型，包括对象。可以向现有对象添加新属性。| [properties]([enabled](https://www.elastic.co/guide/en/elasticsearch/reference/current/properties.html))\n\n## 3、空间/地址位置 (GEO)\n\n### 3-1、[Geo-point](https://www.elastic.co/guide/en/elasticsearch/reference/current/geo-point.html)\n\n>1、用于lat/lon点的geo_point\n\n>2、请注意，字符串地理点的顺序是lat,lon，而数组地理点的顺序是相反的:lon,lat。\n\n>3、只使用前12个字符，因此在geohash中指定超过12个字符并不会增加精度\n\n#### 支持的参数\n\n参数名称 | 默认值 | 描述 | 详情连接\n--------|-------|-----|----\nignore_malformed | (bool) false | | [ignore_malformed](https://www.elastic.co/guide/en/elasticsearch/reference/current/ignore-malformed.html)\nnull_value | null | | [null_value](https://www.elastic.co/guide/en/elasticsearch/reference/current/null_value.html)\nignore_z_value | |\n\n### 3-2、[Geo-shape](https://www.elastic.co/guide/en/elasticsearch/reference/current/geo-shape.html)\n\n>1、geo_shape用于复杂的形状，如多边形\n\n## 4、特别类型\n\n> 对对应的类型做了特别处理的\n\n### 4-1、[IP](https://www.elastic.co/guide/en/elasticsearch/reference/current/ip.html)\n\n> 用于IPv4和IPv6地址的ip\n\n> 您还可以使用ip_range数据类型在单个字段中存储ip范围。\n\n#### 支持的参数\n\n参数名称 | 默认值 | 描述 | 详情连接\n--------|-------|-----|----\nboost | (int\\|float) 1.0 | | [boost](https://www.elastic.co/guide/en/elasticsearch/reference/current/boost.html)\ndoc_values | (bool) true | true 加快聚合、排序、脚本编写速度。false 节约空间 |  [doc_values](https://www.elastic.co/guide/en/elasticsearch/reference/current/doc-values.html)(默认 true)\nindex | (bool) true | | [index](https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html)\nnull_value | null |  | [null_value](https://www.elastic.co/guide/en/elasticsearch/reference/current/null_value.html)\nstore | (bool) false | | [store](https://www.elastic.co/guide/en/elasticsearch/reference/current/store.html)\n\n### 4-2、完成补全/推荐 ([Completion](https://www.elastic.co/guide/en/elasticsearch/reference/current/search-suggesters.html))\n\n>提供自动完成建议\n\n### 4-3、[Token_count](https://www.elastic.co/guide/en/elasticsearch/reference/current/token-count.html)\n\n>token_count用于计算字符串中的令牌数量\n\n>用于统计做了标记的字段的index数目，该值会一直增加，不会因为过滤条件而减少。\n\n#### 支持的参数\n\n参数名称 | 默认值 | 描述 | 详情连接\n--------|-------|-----|----\nanalyzer |  | 分析器，必需的。请使用没有令牌筛选器的分析器。 | [analyzer](https://www.elastic.co/guide/en/elasticsearch/reference/current/analyzer.html)\nenable_position_increments | (bool) true |\nboost | (int\\|float) 1.0 | | [boost](https://www.elastic.co/guide/en/elasticsearch/reference/current/boost.html)\ndoc_values | (bool) true | true 加快聚合、排序、脚本编写速度。false 节约空间 |  [doc_values](https://www.elastic.co/guide/en/elasticsearch/reference/current/doc-values.html)(默认 true)\nindex | (bool) true | | [index](https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html)\nnull_value | null | | [null_value](https://www.elastic.co/guide/en/elasticsearch/reference/current/null_value.html)\nstore | (bool) false | | [store](https://www.elastic.co/guide/en/elasticsearch/reference/current/store.html)\n\n### 4-4、[mapper-murmur3](https://www.elastic.co/guide/en/elasticsearch/plugins/7.4/mapper-murmur3.html)\n\n### 4-5、[mapper-annotated-text](https://www.elastic.co/guide/en/elasticsearch/plugins/7.4/mapper-annotated-text.html)\n\n### 4-6、[Join](https://www.elastic.co/guide/en/elasticsearch/reference/current/parent-join.html)\n\n>父子文档\n\n### 4-7、[Rank_feature](https://www.elastic.co/guide/en/elasticsearch/reference/current/rank-feature.html)\n\n>1、来存储特征向量，数据不能为0和负数，查询时只能使用rank_feature query，该字段主要为支持后续机器学习相关功能做准备\n\n>2、rank_feature字段不支持查询、排序或聚合。\n 它们只能在rank_feature查询中使用。\n\n### 4-8、[Dense vector](https://www.elastic.co/guide/en/elasticsearch/reference/current/dense-vector.html)\n\n>他的功能是实验性的，在将来的版本中可能会完全改变或删除\n\n### 4-9、查询期间的即时搜索 ([Search-as-you-type](https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-types.html))\n\n#### 支持的参数\n\n参数名称 | 默认值 | 描述 | 详情连接\n--------|-------|-----|----\nanalyzer |  | 分析器，它应该用于分析的字符串字段，无论是在索引时还是在搜索时(除非被search_analyzer覆盖)。默认索引分析器或标准分析器。 | [analyzer](https://www.elastic.co/guide/en/elasticsearch/reference/current/analyzer.html)\nindex_options | (docs/freqs/positions/offsets) positions | [index_options](https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-index.html)(默认 docs)\nnorms | (bool) true | [norms](https://www.elastic.co/guide/en/elasticsearch/reference/current/norms.html)\nstore | (bool) false | | [store](https://www.elastic.co/guide/en/elasticsearch/reference/current/store.html)\nsearch_analyzer | 默认为分析器设置 | 在分析字段的搜索时使用的分析器。默认为分析器设置。 | [search_analyzer](https://www.elastic.co/guide/en/elasticsearch/reference/current/search-analyzer.html)\nsearch_quote_analyzer | 默认设置为search_analyzer | 当遇到短语时，应该在搜索时使用的分析器。默认设置为search_analyzer。 | [](https://www.elastic.co/guide/en/elasticsearch/reference/current/analyzer.html#search-quote-analyzer)\nsimilarity | BM25 |  | [similarity](https://www.elastic.co/guide/en/elasticsearch/reference/current/similarity.html)\nterm_vector | no |  | [term_vector](https://www.elastic.co/guide/en/elasticsearch/reference/current/term-vector.html)\n\n### 4-10、别名 ([Alias](https://www.elastic.co/guide/en/elasticsearch/reference/current/alias.html))\n\n>1、定义现有字段的别名。\n\n>2、对于别名的目标有一些限制:\n 目标必须是一个具体的字段，而不是对象或另一个字段别名。\n 目标字段必须在创建别名时存在。\n 如果定义了嵌套对象，则字段别名必须具有与其目标相同的嵌套范围\n\n### 4-11、[Flattened](https://www.elastic.co/guide/en/elasticsearch/reference/current/flattened.html)\n\n>1、允许将整个JSON 对象作为单个字段建立索引。\n\n>2、只允许基本查询(term, terms, and terms_set / prefix / range / match and multi_match / query_string and simple_query_string / exists)，不支持数值范围查询或高亮显示。有关这些限制的进一步信息可以在受支持的操作部分中找到。\n\n#### 支持的参数\n\n参数名称 | 默认值 | 描述 | 详情连接\n--------|-------|-----|----\nboost | (float) 1.0 | | [boost](https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-boost.html)\ndepth_limit | (int) 20 | 就嵌套内部对象而言，平坦对象字段允许的最大深度。如果扁平对象字段超过此限制，则会抛出错误。默认为20。\neager_global_ordinals | (bool) false | | [eager_global_ordinals](https://www.elastic.co/guide/en/elasticsearch/reference/current/eager-global-ordinals.html)\ndoc_values | (bool) true | | [doc_values](https://www.elastic.co/guide/en/elasticsearch/reference/current/doc_values.html)\nignore_above | | 超过此限制的叶子值将不被索引。默认情况下，没有限制，所有值都将被索引。注意，这个限制适用于扁平对象字段中的叶值，而不是整个字段的长度。 | [ignore_above](https://www.elastic.co/guide/en/elasticsearch/reference/current/ignore-above.html)\nindex_options | (docs/freqs/positions/offsets) docs | | [index_options](https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-index.html)(默认 docs)\nnull_value | null | | [null_value](https://www.elastic.co/guide/en/elasticsearch/reference/current/null-value.html)\nsimilarity | BM25 | | [similarity](https://www.elastic.co/guide/en/elasticsearch/reference/current/similarity.html)\nsplit_queries_on_whitespace | (bool) false | | [最后一行](https://www.elastic.co/guide/en/elasticsearch/reference/current/flattened.html)\n\n### 4-12、[Shape](https://www.elastic.co/guide/en/elasticsearch/reference/current/shape.html)\n\n>形状数据类型便于对任意x、y笛卡尔形状(如矩形和多边形)进行索引和搜索。它可用于索引和查询坐标位于二维平面坐标系中的几何图形。\n\n## 5、数组 ([array](https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-types.html))\n\n>在Elasticsearch中，数组不需要专用字段数据类型。\n 默认情况下，任何字段都可以包含零个或多个值，但是数组中的所有值必须具有相同的数据类型。\n 看到数组。","tags":["Elasticsearch"]},{"title":"开放 GraphQL 测试","url":"/jingjie.github.io/2019/12/05/开放 GraphQL 测试/","content":"\n# GraphQL 测试地址：\n\n### [https://www.nicefutureworld.com/graphql-ui](https://www.nicefutureworld.com/graphql-ui)\n\n----\n\n## 例子：\n\n### 获取单条数据\n\n![2b40efa9e431f33062d5259b3894a14.png](https://www.nicefutureworld.com/storage/article/2019/07/29/WvsWWtiYnYuA8DR8eujiiqpDhDQcY14NufIBMgBE.png)\n\n### 获取多条数据\n\n![fd5993bc37b5133ffc77957dd9687b8.png](https://www.nicefutureworld.com/storage/article/2019/07/29/dz2jExaIauH1uWMerv3I1xxtrLIdpqL81kyzvbsM.png)\n\n### 获取分页数据\n\n![b2280d57dd13707a605cce9f81fe2e0.png](https://www.nicefutureworld.com/storage/article/2019/07/29/2cBCrdKzFooCgR6fEQcgind0MgrxyRyP9yVDY2mY.png)\n\n### 一次执行多个查询\n\n![27ef2c456169538b75275fdd806b8aa.png](https://www.nicefutureworld.com/storage/article/2019/07/29/MKfohMBLZBu54wEBmzteS8SbVwpvOsDz4ijVgHA2.png)\n\n### 更新数据\n\n![59100dac35ca2875d4423d42f22172a.png](https://www.nicefutureworld.com/storage/article/2019/07/29/MhOrSqVqfDP2ivVVGwZoOcaGLz0TtptBdL8cI9fe.png)","tags":["GraphQL"]},{"title":"对 SQL 进行优化和改写的自动化工具","url":"/jingjie.github.io/2019/12/05/对 SQL 进行优化和改写的自动化工具/","content":"[SQL 进行优化和改写的自动化工具](https://github.com/XiaoMi/soar)\n[优化工具-命令版本](https://www.jianshu.com/p/3a86c909afc1)\n[扩展包](https://github.com/guanguans/soar-php)","tags":["MySQL"]},{"title":"祖孙文档下的  routing","url":"/jingjie.github.io/2019/12/05/祖孙文档下的  routing/","content":"### 官方文档\n\n[routing 官方文档](https://www.elastic.co/guide/en/elasticsearch/reference/6.4/mapping-routing-field.html)\n\n**routing ** 为路由\n\n通过为每个文档指定自定义路由值，把文档索引到指定分片，未指定路由值时，**默认** _id 为 **routing** 值\n\n### 在父子文档下或祖孙文档下\n\na 为 b 的父文档，b 为 c 的父文档，c 为 a 的孙辈文档，这时 _routing 的定义如下：\n\n```\n// 定义索引\nPUT my_index\n{\n  \"mappings\": {\n    \"_doc\": {\n      \"properties\": {\n        \"my_join_field\": {\n          \"type\": \"join\",\n          \"relations\": {\n            \"a\": ['b']  \n            \"b\": \"c\" \n          }\n        }\n      }\n    }\n  }\n}\n\n// 插入 a 文档\nPUT my_index/_doc/1?routing=space1&refresh \n{\n  \"text\": \"This is a vote\",\n  \"my_join_field\":\"a\"\n}\n\n// 插入 b 文档 \nPUT my_index/_doc/2?routing=space1&refresh \n{\n  \"text\": \"This is a vote\",\n  \"my_join_field\":{\n\t  \"name\": \"b\",\n\t\t\"parent\": \"1\"\n\t}\n}\n\n// 插入 c 文档 \nPUT my_index/_doc/3?routing=space1&refresh \n{\n  \"text\": \"This is a vote\",\n  \"my_join_field\":{\n\t  \"name\": \"c\",\n\t\t\"parent\": \"2\"\n\t}\n}\n```\n\na、b、c 文档即都在 routing=space1 分片上，这时 a、b、c 之间的关系才成立，如果不在同一个 routing=space1 分片上，则关系不成立。","tags":["Elasticsearch"]},{"title":"慢查询","url":"/jingjie.github.io/2019/12/05/慢查询/","content":"# 慢查询\n\n##### [01慢查询的影响](#influence)\n\n##### [02查看慢查询](#view)\n\n##### [03慢查询优化步骤](#)\n\n### <span id=\"influence\">01 慢查询的影响</span>\n\n##### 为什么要关注慢查询？\n\n之所以关注慢查询，是因为慢查询会导致以下影响：\n\n+ 数据库 cpu 负载高\n+ IO 负载高导致服务器卡住，拖慢数据库性能\n+ Sql 执行计划不合适，执行耗时过长\n+ 数据库锁的增多，影响正常的 DDL 和 DML 操作\n\n### <span id=\"view\">02 查看慢查询</span>\n\n##### 如何查看慢日志？\n\n查看慢查询日志，可以按照以下几步：\n\n+ 查看 my.cnf 文件，通过 slow_query_log_file 参数定位慢查询日志的位置\n+ 通过 vim 直接打开慢查询日志对其进行单条慢sql分析\n+ 通过 mysqldumpslow 或 pt-query-digest 工具对慢查询日志进行汇总分析\n\n### <span id=\"view\">03 慢查询优化步骤</span>\n\n##### 针对一个特定的慢sql如何优化？\n\n针对特定的慢sql，主要要经过以下几步分析：\n\n+ 查看 SQL 执行计划: explain sql\n+ 查看表的索引: show index from tb_name\n+ 查看表结构: show create table tb_name\n+ 通过 profiling 看看 sql 耗时主要花在哪里？\n+ 通过 Optimizer Trace 观察 sql 的执行过程，观察 sql 执行计划选取的依据","tags":["MySQL"]},{"title":"基于 Token 的验证原理","url":"/jingjie.github.io/2019/12/05/基于 Token 的验证原理/","content":"### 基于服务器的验证\n\n我们都是知道HTTP协议是无状态的，这种无状态意味着程序需要验证每一次请求，从而辨别客户端的身份。\n\n在这之前，程序都是通过在服务端存储的登录信息来辨别请求的。这种方式一般都是通过存储Session来完成。\n\n随着Web，应用程序，已经移动端的兴起，这种验证的方式逐渐暴露出了问题。尤其是在可扩展性方面。\n\n### 基于服务器验证方式暴露的一些问题 \n\n1、session：每次认证用户发起请求时，服务器需要去创建一个记录来存储信息。当越来越多的用户发请求时，内存的开销也会不断增加。\n\n2、可扩展性：在服务端的内存中使用Seesion存储登录信息，伴随而来的是可扩展性问题。\n\n3、CORS(跨域资源共享)：当我们需要让数据跨多台移动设备上使用时，跨域资源的共享会是一个让人头疼的问题。在使用Ajax抓取另一个域的资源，就可以会出现禁止请求的情况。\n\n4、CSRF(跨站请求伪造)：用户在访问银行网站时，他们很容易受到跨站请求伪造的攻击，并且能够被利用其访问其他的网站。\n\n在这些问题中，可扩展行是最突出的。因此我们有必要去寻求一种更有行之有效的方法。\n\n### 基于Token的验证原理\n\n基于Token的身份验证是无状态的，我们不将用户信息存在服务器或Session中。\n\n这种概念解决了在服务端存储信息时的许多问题\n\nNoSession意味着你的程序可以根据需要去增减机器，而不用去担心用户是否登录。\n\n基于Token的身份验证的过程如下:\n\n>1.用户通过用户名和密码发送请求。\n\n>2.程序验证。\n\n>3.程序返回一个签名的token 给客户端。\n\n>4.客户端储存token,并且每次用于每次发送请求。\n\n>5.服务端验证token并返回数据。\n\n每一次请求都需要token。token应该在HTTP的头部发送从而保证了Http请求无状态。我们同样通过设置服务器属性Access-Control-Allow-Origin:* ，让服务器能接受到来自所有域的请求。\n\n**Notice：需要注意的是，在ACAO头部标明(designating)*时，不得带有像HTTP认证，客户端SSL证书和cookies的证书。**\n\n### Token的优势\n\n#### 无状态、可扩展 \n\n在客户端存储的Tokens是无状态的，并且能够被扩展。基于这种无状态和不存储Session信息，负载负载均衡器能够将用户信息从一个服务传到其他服务器上。\n\n如果我们将已验证的用户的信息保存在Session中，则每次请求都需要用户向已验证的服务器发送验证信息(称为Session亲和性)。用户量大时，可能会造成一些拥堵。\n\n但是不要着急。使用tokens之后这些问题都迎刃而解，因为tokens自己hold住了用户的验证信息。\n\n#### 安全性\n\n请求中发送token而不再是发送cookie能够防止CSRF(跨站请求伪造)。即使在客户端使用cookie存储token，cookie也仅仅是一个存储机制而不是用于认证。不将信息存储在Session中，让我们少了对session操作。\n\ntoken是有时效的，一段时间之后用户需要重新验证。我们也不一定需要等到token自动失效，token有撤回的操作，通过token revocataion可以使一个特定的token或是一组有相同认证的token无效。\n\n#### 可扩展性\n\nTokens能够创建与其它程序共享权限的程序。例如，能将一个随便的社交帐号和自己的大号(Fackbook或是Twitter)联系起来。当通过服务登录Twitter(我们将这个过程Buffer)时，我们可以将这些Buffer附到Twitter的数据流上(we are allowing Buffer to post to our Twitter stream)。\n\n使用tokens时，可以提供可选的权限给第三方应用程序。当用户想让另一个应用程序访问它们的数据，我们可以通过建立自己的API，得出特殊权限的tokens。\n\n#### 多平台跨域\n\n我们提前先来谈论一下CORS(跨域资源共享)，对应用程序和服务进行扩展的时候，需要介入各种各种的设备和应用程序。\n\nHaving our API just serve data, we can also make the design choice to serve assets from a CDN. This eliminates the issues that CORS brings up after we set a quick header configuration for our application.\n\n只要用户有一个通过了验证的token，数据和资源就能够在任何域上被请求到。\n\nAccess-Control-Allow-Origin: *\n\n基于标准创建token的时候，你可以设定一些选项。我们在后续的文章中会进行更加详尽的描述，但是标准的用法会在JSON Web Tokens体现。\n\n最近的程序和文档是供给JSON Web Tokens的。它支持众多的语言。这意味在未来的使用中你可以真正的转换你的认证机制。\n\n[原文](https://mp.weixin.qq.com/s?__biz=MzUyODkwMTQyNg==&mid=2247486884&idx=1&sn=5405805d6a2a3b6b58c88724442696ae&chksm=fa6879f9cd1ff0ef72ca7940176384860ac9e3f10e55a12b0c96a54b599351609a9762af346a&mpshare=1&scene=1&srcid=&sharer_sharetime=1570499920879&sharer_shareid=323f2ae4d24129fb6fcdd70ff10bf462&key=ff951f2f31774ef121a174bba6aa04d2a7f5f9067ec6fbad1152805e48ea6d8202e644dd517b76f05f8f870d832265325c4ebc199a488e1304cad9336e439c569837bb492e796bbf114a5b7405483584&ascene=1&uin=MjI5MjExNzkwOA%3D%3D&devicetype=Windows+10&version=62060844&lang=zh_CN&pass_ticket=ImS9Gw0KaThrIsyw5GAupNQu6ULGiS8CGe%2B6O1IusxUiqo2EqrKtpu8%2B9Mopa44H)","tags":["Laravel"]},{"title":"whereRaw() 与 where(DB：：raw()) 的区别","url":"/jingjie.github.io/2019/12/05/whereRaw() 与 where(DB：：raw()) 的区别/","content":"## whereRaw() 与 where(\\DB::raw()) 的区别\n\n##### **测试版本：Laravel5.5**\n=================\n\n##### where(\\DB::raw()) 截图\n\n![file](https://cdn.learnku.com/uploads/images/201811/05/23047/b2yFtrnzRO.png!large)\n![file](https://cdn.learnku.com/uploads/images/201811/05/23047/HlCBydLajS.png!large)\n\n##### whereRaw() 截图\n\n![file](https://cdn.learnku.com/uploads/images/201811/05/23047/gMfYBGpkhL.png!large)\n![file](https://cdn.learnku.com/uploads/images/201811/05/23047/kUTdLMt66t.png!large)","tags":["Laravel"]},{"title":"异常","url":"/jingjie.github.io/2019/12/05/Laravel 特殊异常结果记录/","content":"\n先做记录，有时间后做异常排查，代码：\n\n``` PHP\n<?php\n$raffle_members = RaffleMember::query()->where('raffle_id',148)->paginate();\n\t\n// 使用 load 或 with \n$raffle_members->load( [\n\t\t\t\t\t\t\t\t   'raffle:id,quota,used_quota,end_at,receive_prize_at,status,must_object_id,must_object_type,goods_id,user_id',\n\t\t\t\t\t\t\t\t   'raffle.clothe:id,describe,pic_id',\n\t\t\t\t\t\t\t\t   'raffle.clothe.cover:id,clothing_id,pic',\n\t\t\t\t\t\t\t\t   'raffle.receivePrize',\n\t\t\t\t\t\t\t\t   'raffle.shortVideo:id,cover_url,desc,title,object_id,object_type,video_url',\n\t\t\n\t\t\t\t\t\t\t   ] );\n\t\t\n$array = [];\n$raffle_members->transform( function ( $raffle_member, $key ) use ( &$array ) {\n\tif ( $raffle_member->raffle->receivePrize ) {\n\t\tif ( $raffle_member->raffle->receivePrize->user_id === $raffle_member->user_id &&  array_get($raffle_member->raffle->receivePrize,'rest.raffle_order_item_id') && !in_array( $raffle_member->raffle->id, $array ) ) {\n\t\t\t$raffle_member->raffle->receivePrize->is_receive_prize = true;\n\t\t\t$array[] = $raffle_member->raffle->id;\n\t\t} else {\n\t\t\t$raffle_member->raffle->receivePrize->is_receive_prize = false;\n\t\t}\n\t}\n\n\treturn $raffle_member;\n} );\n\t\t\nreturn $raffle_members;\n\n```\n\n返回结果描述及临时解决方案\n\n```\n1、使用了 load 或 with 『预加载』关联数据，is_receive_prize 的结果将始终 false\n2、未使用 load 或 with 『预加载』关联数据，is_receive_prize 的结果跟预期一致，但有 N + 1 问题\n3、临时解决方案：使用『预加载』后再 toArray，再循环，问题得到解决\n```","tags":["Laravel"]},{"title":"Linux 性能分析工具图","url":"/jingjie.github.io/2019/12/05/Linux 性能分析工具图/","content":"这个图是 Linux 性能分析最重要的参考资料之一，它告诉你 Linux 不同子系统出现性能问题，应该使用什么样的工具来观察与分析，比如 IO 性能问题，可能参考 IO 子系统，可以使用 iostat、iotop、blktrace等工具分析磁盘 IO 的瓶颈\n\n![file](https://cdn.learnku.com/uploads/images/201902/26/23047/ZFqUsfY97n.png!large)\n\n![file](https://cdn.learnku.com/uploads/images/201902/26/23047/KjnB62oumY.png!large)\n\n![file](https://cdn.learnku.com/uploads/images/201902/26/23047/lSPhVAMDuI.png!large)","tags":["Linux"]},{"title":"MySQL 隔离级别","url":"/jingjie.github.io/2019/12/05/MySQL 隔离级别/","content":"\n### MySQL\n\n级别 | 别名 | 中文名 |脏读 | 不可重复读 | 幻读 | 并发性能 | 说明 \n---|-- |-- |-- | --- |-- |--\nREAD UNCOMMITTED | RU | 读未提交 | YES | YES | YES | 1 级（高）|\nREAD COMMITTED | RC | 读提交 | NO | YES | YES | 2 级 |\nREPEATABLE READ | RR | 可重复读 | NO | NO | NO | 3 级  | 间隙锁 NK 解决了幻读，默认级别\nSERIALIZABLE | | 串行化 | NO | NO | NO | 4 级（低）|\n\n- RC 为解决『脏读』\n- RR 为解决『不可重复读』\n- 间隙锁（NK）为解决『幻读』","tags":["MySQL"]},{"title":"【缓存穿透、缓存击穿、缓存雪崩、热点数据失效】问题的解决方案","url":"/jingjie.github.io/2019/12/05/【缓存穿透、缓存击穿、缓存雪崩、热点数据失效】问题的解决方案/","content":"# 阿里一面：关于【缓存穿透、缓存击穿、缓存雪崩、热点数据失效】问题的解决方案\n\n来自：石杉的架构笔记\n\n### 1、前言\n\n昨天晚上接到阿里的电面电话，过程中就问到了关于缓存相关的问题。\n\n虽然以前接触过，多多少少了解了一些。但是之前自己并没有好好记录这些内容，在真正面试的时候，并没有回答得出来。今天记录一下，长长记性。\n\n在我们的平常的项目中多多少少都会使用到缓存，因为一些数据我们没有必要每次查询的时候都去查询到数据库。\n\n特别是高 QPS 的系统，每次都去查询数据库，对于你的数据库来说将是灾难。\n\n今天我们不牵涉多级缓存的知识，就把系统使用到的缓存方案，不管是一级还是多级的都统称为缓存，主要是为了讲述使用缓存的时候可能会遇到的一些问题以及一些解决办法。\n\n当我们查询一条数据时，先去查询缓存，如果缓存有就直接返回，如果没有就去查询数据库，然后返回。这种情况下就可能会出现一些现象。\n\n### 2、缓存穿透\n\n##### 2.1 什么是缓存穿透\n\n正常情况下，我们去查询数据都是存在。\n\n那么请求去查询一条压根儿数据库中根本就不存在的数据，也就是缓存和数据库都查询不到这条数据，但是请求每次都会打到数据库上面去。\n\n这种查询不存在数据的现象我们称为缓存穿透。\n\n##### 2.2 穿透带来的问题\n\n试想一下，如果有黑客会对你的系统进行攻击，拿一个不存在的id 去查询数据，会产生大量的请求到数据库去查询。可能会导致你的数据库由于压力过大而宕掉。\n\n##### 2.3 解决方案\n\n+ 1、缓存空值\n\n\t> 之所以会发生穿透，就是因为缓存中没有存储这些空数据的 key。从而导致每次查询都到数据库去了。\n\n\t> 那么我们就可以为这些 key 对应的值设置为 null 丢到缓存里面去。后面再出现查询这个 key 的请求的时候，直接返回 null 。\n\n\t> 这样，就不用在到数据库中去走一圈了，但是别忘了设置过期时间。\n\t\n+ 2、BloomFilter （布隆过滤器）\n\n\t> BloomFilter 类似于一个hbase set 用来判断某个元素（key）是否存在于某个集合中。\n\n\t> 这种方式在大数据场景应用比较多，比如 Hbase 中使用它去判断数据是否在磁盘上。还有在爬虫场景判断url 是否已经被爬取过。\n\n\t> 这种方案可以加在第一种方案中，在缓存之前在加一层 BloomFilter ，在查询的时候先去 BloomFilter 去查询 key 是否存在，如果不存在就直接返回，存在再走查缓存 -> 查 DB。\n\t\n##### 2.4 如何选择\n\n针对于一些恶意攻击，攻击带过来的大量 key 是不存在的，那么我们采用第一种方案就会缓存大量不存在 key 的数据。\n\n此时我们采用第一种方案就不合适了，我们完全可以先对使用第二种方案进行过滤掉这些 key。\n\n针对这种 key 异常多、请求重复率比较低的数据，我们就没有必要进行缓存，使用第二种方案直接过滤掉。\n\n而对于空数据的 key 有限的，重复率比较高的，我们则可以采用第一种方式进行缓存\n\n### 3、缓存击穿\n\n##### 3.1 什么是击穿\n\n缓存击穿是我们可能遇到的第二个使用缓存方案可能遇到的问题。\n\n在平常高并发的系统中，大量的请求同时查询一个 key 时，此时这个 key 正好失效了，就会导致大量的请求都打到数据库上面去。这种现象我们称为 **缓存击穿**。\n\n##### 3.2 会带来什么问题\n\n会造成某一时刻数据库请求量过大，压力剧增。\n\n##### 3.3 如何解决\n\n上面的现象是多个线程同时去查询数据库的这条数据，那么我们可以在第一个查询数据的请求上使用一个 互斥锁来锁住它。\n\n其他的线程走到这一步拿不到锁就等着，等第一个线程查询到了数据，然后做缓存。后面的线程进来发现已经有缓存了，就直接走缓存。\n\n### 4、缓存雪崩\n\n##### 4.1 什么是缓存雪崩\n\n缓存雪崩的情况是说，当某一时刻发生大规模的缓存失效的情况，比如你的缓存服务宕机了，会有大量的请求进来直接打到DB上面。结果就是DB 称不住，挂掉\n\n##### 4.2 解决方案\n\n+ 1、事前： 使用集群缓存，保证缓存服务的高可用\n\n\t> 这种方案就是在发生雪崩前对缓存集群实现高可用，如果是使用 Redis，可以使用 主从+哨兵 ，Redis Cluster 来避免 Redis 全盘崩溃的情况。\n\t\n+ 2、事中：ehcache 本地缓存 + Hystrix 限流 & 降级,避免 MySQL 被打死\n\n\t> 使用 ehcache 本地缓存的目的也是考虑在 Redis Cluster 完全不可用的时候，ehcache 本地缓存还能够支撑一阵。\n\n\t> 使用 Hystrix进行限流 & 降级 ，比如一秒来了5000个请求，我们可以设置假设只能有一秒 2000个请求能通过这个组件，那么其他剩余的 3000 请求就会走限流逻辑。\n\n\t> 然后去调用我们自己开发的降级组件（降级），比如设置的一些默认值呀之类的。以此来保护最后的 MySQL 不会被大量的请求给打死。\n\t\n+ 3、事后：开启Redis持久化机制，尽快恢复缓存集群\n\n\t一旦重启，就能从磁盘上自动加载数据恢复内存中的数据。\n\n### 5、解决热点数据集中失效问题\n\n我们在设置缓存的时候，一般会给缓存设置一个失效时间，过了这个时间，缓存就失效了。\n\n对于一些热点的数据来说，当缓存失效以后会存在大量的请求过来，然后打到数据库去，从而可能导致数据库崩溃的情况。\n\n##### 5.1 解决方案\n\n+ 1、设置不同的失效时间\n\n\t> 为了避免这些热点的数据集中失效，那么我们在设置缓存过期时间的时候，我们让他们失效的时间错开。\n\n\t> 比如在一个基础的时间上加上或者减去一个范围内的随机值。\n\t\n+ 2、互斥锁\n\n\t> 结合上面的击穿的情况，在第一个请求去查询数据库的时候对他加一个互斥锁，其余的查询请求都会被阻塞住，直到锁被释放，从而保护数据库。\n\n\t> 但是也是由于它会阻塞其他的线程，此时系统吞吐量会下降。需要结合实际的业务去考虑是否要这么做。","tags":["Redis"]},{"title":"从 Laravel 代码理解 IOC","url":"/jingjie.github.io/2019/12/05/从 Laravel 代码理解 IOC/","content":"# IOC 容器\n\n## 入口文件 index.php\n\n```\n1、加载框架依赖\n2、创建 app 容器\n3、解析 Http\\Kernel.php 内核\n4、执行请求操作\n5、返回结果\n6、终止应用程序\n```\n![file](https://cdn.learnku.com/uploads/images/201808/23/23047/kzuImouMTL.png?imageView2/2/w/1240/h/0)\n\n## app.php 文件（require_once __DIR__.'/../bootstrap/app.php'）\n\n```\n1、创建容器\n2、绑定 Http\\Hernel.php 到容器\n3、绑定 Console\\Kernel.php 到容器\n4、绑定 Exception\\Hadnler.php 到容器\n5、返回 app 容器\n```\n![file](https://cdn.learnku.com/uploads/images/201808/23/23047/muipVNnQMe.png?imageView2/2/w/1240/h/0)\n\n## app 容器\n\n### 打印 app 容器\n\n```\n1、serviceProviders 属性\n    用于存放所有已经注册完毕的服务提供者\n\n2、loadedProviders 属性\n    跟 serviceProviders 数组类似，标记方式不同\n\n3、deferredServices 属性\n    用来储存所有延迟加载服务提供者\n\n4、resolved 属性\n    服务解析完毕，都会在 resolved 属性里面存入一条记录，表示绑定已经解析过\n\n5、bindings 属性\n    记录所有绑定\n\n6、instances 属性\n    在第一次解析绑定时，如果 shared 为 true则都会往 instances 属性里面存入一条记录\n\n7、aliases 属性\n    服务绑定的别名，别名数量无限制\n\n```\n![file](https://cdn.learnku.com/uploads/images/201808/23/23047/VtCKhcrcyC.png?imageView2/2/w/1240/h/0)\n\n## 注册服务提供者\n\n注册服务提供者只需要继承 ServiceProvider 抽象类即可（放在那儿都可以），并在 config/app.php providers 数组\n里面注册或使用 app()->register(TestProvider::class)（此方法 $defer 属性无效） 即可\n\n```\n1、继承 ServiceProvider 抽象类\n\n2、创建 register 方法并使用 app 容器绑定服务（可绑定任意数量服务）\n\n3、创建 boot 方法，初始化所绑定的服务\n\n4、$defer 属性为是否延迟加载，为 true 会存入到 deferredServices 属性，程序注册时会调用 ServicePr\n\tovider 抽象类的 isDeferred() 方法 『必须在config/app.php providers中注册』\n\n5、事件触发注册服务提供者，ServiceProvider 抽象类的 when 方法返回一个数组，数组里面包含事件\n\t名称 如：[TestEvent::class]，『$defer 必须为 true』\n\n注意：\n    PHP 在处理请求前，都会从入口文件把所有 PHP 文件都扫描一遍。Laravel 为了性能考虑，会在第一\n\t次初始化的时候，把所有服务提供者都缓存到 bootstrap/cache/service.php 文件里面，所以有时候在\n\t改或增了服务提供者，刷新可能不生效，这有可能是缓存所致，这时把 service.php 与 packages.php\n\t删除再重试\n\n```\n\n## 注册服务提供者别名\n\napp()->alias('testProvider','test')  别名数量无限制\n\n![file](https://cdn.learnku.com/uploads/images/201808/23/23047/8D6amdy1ZF.png?imageView2/2/w/1240/h/0)\n\n## app 容器绑定\n\n1、app()->bind($abstract, $concrete = null, $shared = false)\n    第一个参数是服务绑定名称，第二个参数是绑定结果（参数类型：\\Closure|string|null），第三个参数是否共享（类似\n\t单例），默认为 false，第二个参数，如果是非闭包，内部会包裹上闭包，好处是延迟加载，节约空间\n\n![file](https://cdn.learnku.com/uploads/images/201808/23/23047/4cieFAedyN.png?imageView2/2/w/1240/h/0)\n\n2、app()->singleton($abstract, $concrete = null)\n    第一个参数是服务绑定名称，第一个参数是绑定结果，在内部是调用了 app()->bind($abstract, $concrete = null, true)，\n\t第三个参数为 true\n\t\n ![file](https://cdn.learnku.com/uploads/images/201808/23/23047/Qer6WAKPqD.png?imageView2/2/w/1240/h/0)\n\n3、app()['test'] = function(){ return 'test' }\n    使用了 PHP ArrayAccess 接口，在内容调用了 app()->bind() 方法，第三个参数为 false\n\n![file](https://cdn.learnku.com/uploads/images/201808/23/23047/HKUVw8Y5RP.png?imageView2/2/w/1240/h/0)\n![file](https://cdn.learnku.com/uploads/images/201808/23/23047/d82lF7Nhrz.png?imageView2/2/w/1240/h/0)\n\t\n4、app()->instance('test',实例)\n    绑定一个实例，跟上面三个比，就是少了一个闭包\n\n## app 容器解析\n\n```\n1、app($abstract, $parameters = [])\n    第一个参数是服务绑定的名称或别名，第二个参数为上下文名称或别名\n    \n2、app()->make($abstract, $parameters = [])\n    同上\n\n3、app()[$abstract]\n    只有第一个参数，使用了 PHP ArrayAccess 接口\n\t\n```\n\n\n## DI 依赖注入\n\nDI 是 IOC 的一种实现，DI 是一种设计模式，IOC 是一种设计思想，DI 实现原理是使用 PHP 反射机制来反射出相应依赖对\n象名称，通过 aliases 属性得到服务名称，然后从容器解析出服务实例，最后传入对应方法，这个过程就是所谓的依赖注入\n\n![file](https://cdn.learnku.com/uploads/images/201808/23/23047/AihlK26IDc.png?imageView2/2/w/1240/h/0)\n![file](https://cdn.learnku.com/uploads/images/201808/23/23047/VwWEUNfPIv.png?imageView2/2/w/1240/h/0)\n\n## 总结\n\nLaravel 是一个组件式框架，实现了高度解耦，再使用 IOC 容器来管理解耦后的组件，我把这个容器理解为使用了对象的高级注册树，当组件越来越多时，那么这个容器对象不是越来越大吗？所以 Laravel 使用了闭包来延迟加载，但是有个问题，如果每次获取都去 new 一次，不是很浪费时间与空间吗？在能满足需求的情况下，能不能只 new 一次（类似单例），所以 Laravel 又引入了 shared 来实现单例，用 instances 属性来保存单例（服务在生命周期内，shared 不可更改，而且 Laravel 大部分服务 shared 都为 true），现在又有个需求，当某个动作发生时，就触发服务加载？所以 Laravel 又加入了 when 方法来绑定事件，前提是这个服务 shared 必须为 true。","tags":["Laravel"]},{"title":"Laravel job 进程管理工具 Supervisor","url":"/jingjie.github.io/2019/12/05/Laravel job 进程管理工具 Supervisor/","content":"\n# Laravel job 进程管理工具 Supervisor\n\n## 系统\n\nCentOS Linux release 7.4.1708\nHomestead 4.15 Ubuntu 18.04 LTS\n\n## Supervisor 安装\n\neasy_install supervisor\n\n```shell\nsudo easy_install supervisor\n```\n\n## Supervisor 配置\n\n1、生成新主配置文件\n\n```shell\necho_supervisord_conf > /etc/supervisord.conf // 需要 root 限制，sudo 不管用\n```\n\n2、修改 supervisord.conf 主配置文件\n\n```shell\n·\n·\n[unix_http_server]\nfile=/var/run/supervisor.sock   ; the path to the socket file\n·\n·\n[supervisorctl]\nserverurl=unix:///var/run/supervisor.sock ; use a unix:// URL  for a unix socket\n·\n·\n[supervisord]\nlogfile=/var/log/supervisord.log ; main log file; default $CWD/supervisord.log\n·\n·\npidfile=/var/run/supervisord.pid ; supervisord pidfile; default supervisord.pid\n·\n·\n[include]\nfiles = /etc/supervisor/*.conf\n```\n\n3、启动 supervisor（确保9001端口未被占用）\n\n```shell\nsudo supervisord -c /etc/supervisord.conf\n```\n\n4、创建第二步对应的文件\n\n```shell\nsudo touch  /var/run/supervisor.sock\nsudo chmod 777 /var/run/supervisor.sock\nsudo touch /var/log/supervisord.log  // 已经存在再次创建也没影响\nsudo chmod 777 /run\nsudo chmod 777 /var/log\n```\n\n5、创建 supervisor 项目配置文件\n\n```shell\n// 查看 /etc/supervisord.conf 文件\n[include]\nfiles = /etc/supervisor/*.conf // 这个路径放置项目对应的 supervisor 配置文件\n```\n\n```shell\n// 在 /etc/supervisor/ 目录下创建以 laravel-worker.conf配置文件（以 .conf 结尾即可)，内容如下\n[program:laravel-worker]\nprocess_name=%(program_name)s_%(process_num)02d\ncommand=php /data/www/laravel/artisan queue:work --sleep=3 --tries=3\nautostart=true\nautorestart=true\nuser=vagrant\nnumprocs=8\nredirect_stderr=true\nstdout_logfile=/var/log/supervisor/laravel-queue.log // 配置文件路径\n```\n\n6、创建 supervisor 项目配置文件日志\n\n```shell\nsudo mkdir /var/log/supervisor\nsudo touch /var/log/supervisor/laravel-queue.log \nsudo chmod 777 /var/log/supervisor/laravel-queue.log\nsudo chown vagrant:vagrant /var/log/supervisor/laravel-queue.log\nsudo chown vagrant:vagrant /var/log/supervisor\n```\n## 启动 supervisor 项目配置文件\n\n```shell\nsudo supervisorctl reread   // 重新加载主配置文件\n\nsudo supervisorctl update // 创建项目配置文件进程组\n\nsudo supervisorctl start laravel-worker:*  // 启动监听进程\n\nsudo supervisorctl status  // 出现以下则成功\nlaravel-worker:laravel-worker_00   RUNNING   pid 12425, uptime 0:04:52\nlaravel-worker:laravel-worker_01   RUNNING   pid 12426, uptime 0:04:52\nlaravel-worker:laravel-worker_02   RUNNING   pid 12427, uptime 0:04:52\nlaravel-worker:laravel-worker_03   RUNNING   pid 12428, uptime 0:04:52\nlaravel-worker:laravel-worker_04   RUNNING   pid 12429, uptime 0:04:52\nlaravel-worker:laravel-worker_05   RUNNING   pid 12430, uptime 0:04:52\nlaravel-worker:laravel-worker_06   RUNNING   pid 12431, uptime 0:04:52\nlaravel-worker:laravel-worker_07   RUNNING   pid 12432, uptime 0:04:52\n\n```\n\n## Note\n\nLaravel Job 代码修改后，需要重启 supervisor 才会生效\n\n## Supervisor 命令\n\n```shell\nsudo supervisorctl status\nsudo supervisorctl stop usercenter\nsudo supervisorctl stop all   //  停止所有\nsudo supervisorctl start usercenter\nsudo supervisorctl restart usercenter\nsudo supervisorctl reread\nsudo supervisorctl update\nsudo supervisorctl  // 进入 cli \n```\n\n[官网](http://supervisord.org/running.html)：http://supervisord.org/running.html\n\n[原文连接](https://learnku.com/laravel/t/3592/using-supervisor-to-manage-laravel-queue-processes?#reply73153)：https://learnku.com/laravel/t/3592/using-supervisor-to-manage-laravel-queue-processes?#reply73153\n\n[参考连接](https://blog.tanteng.me/2017/01/supervisor-laravel-queue/)：https://blog.tanteng.me/2017/01/supervisor-laravel-queue\n\n[参考连接](https://blog.csdn.net/qq_28885149/article/details/79364685)https://blog.csdn.net/qq_28885149/article/details/79364685\n\n[supervisor Web管理界面与开房自启动](http://www.cnblogs.com/lemon-flm/articles/9283664.html)：http://www.cnblogs.com/lemon-flm/articles/9283664.html","tags":["Laravel"]},{"title":"my.conf","url":"/jingjie.github.io/2019/12/05/my.conf/","content":"\n[来源华为云](https://education.huaweicloud.com:8443/courses/course-v1:HuaweiX+CBUCNXD002+2018.5/courseware/248ca4b49f444c65af9c4c387ee0820e/c1449eabdd734057872f655685fc0b1c/?child=first)\n\n## MySQL 技术参数解读和设置\n\n\n### 1、back_log\n\n#### 参数含义\n\n>MySQL每处理一个连接请求的时候都会对应的创建一个新线程，那么在主线程创建新线程期间，如果前端应用有大量的短连接进入到数据库，为了保证当前事务及MySQL本身的稳定性，MySQL不可能无限制的接受新连接进入请求队列。请求队列的大小就是由back_log控制，如果等待的连接数量超过back_log，则将不会接受新的连接请求，所以如果需要MySQL并发处理大量的短连接，需要提高此参数的大小\n\n#### 取值范围\n\n>1--65535\n\n#### 推荐值\n\n>600\n\n#### 注意\n\n>该参数值不能超过MySQL服务器TCP/IP连接的侦听队列的大小。若超过则无效，查看当前系统的TCP/IP连接的侦听队列的大小命令：\n\n>**cat /proc/sys/net/ipv4/tcp_max_syn_backlog**\n\n### 2、binlog_error_action\n\n#### 参数含义\n\n>Binlog_error_action参数控制当不能写binlog时，mysql本身会怎样处理这个状态。设置binlog_error_action=ABORT_SERVER会使mysql在写binlog遇到错误时退出。在ABORT_SERVER模式下，binlog和从库都是安全的。binlog_error_action=IGNORE_ERROR，如果无法写入binlog，mysql会在error.log中记录相关错误信息并强制关闭binlog功能。这会使mysql在不记录binlog的模式下继续运行，导致从库无法继续获取到主库的binlog。\n\n#### 取值范围\n\n>IGNORE_ERROR | ABORT_SERVER\n\n#### 推荐值\n\n>ABORT_SERVER\n\n#### 注意\n\n### 3、binlog_format\n\n#### 参数含义\n\n>该参数控制MySQL是以如何格式记录二进制日志Binlog的。STATEMENT（SBR）：Binlog记录的只是sql语句，日志量最少。ROW（RBR）：Binlog记录完成的数据变更记录，日志量最大，但是最安全的。MIXED（MBR）：MySQL根据一定的规则决定以何种格式记录binlog。在以下场景自动从STATEMENT格式转换为ROW格式。如：UUID(), UDF, AUTO_INCREMENT columns, LOAD_FILE(), USER(), CURRENT_USER(), or CURRENT_USER等等\n\n#### 取值范围\n\n>ROW | MIXED | STATEMENT\n\n#### 推荐值\n\n>ROW\n\n#### 注意\n\n### 4、lower_case_table_names\n\n#### 参数含义\n\n>lower_case_table_names=0 表名存储为给定的大小和比较是区分大小写的\n>lower_case_table_names = 1 表名存储在磁盘是小写的，但是比较的时候是不区分大小写\n>lower_case_table_names=2 表名存储为给定的大小写但是比较的时候是小写的\n>unix,linux下lower_case_table_names默认值为 0 .Windows下默认值是 1 .Mac OS X下默认值是 2\n\n#### 取值范围\n\n>0 | 1\n\n#### 推荐值\n\n>1\n\n#### 注意\n\n### 5、innodb_file_format\n\n#### 参数含义\n\n>控制Innodb引擎的行存储机制。Innodb引擎还支持行数据压缩特性，不过前提是采用Barracuda行存储格式。表空间启用压缩的前提是innodb表空间文件存储格式修改成Barracuda，此外需要修改innodb_file_format_max= Barracuda\n\n#### 取值范围\n\n>Antelope | Barracuda\n\n#### 推荐值\n\n>Barracuda\n\n#### 注意\n\n### 6、max_binlog_size\n\n#### 参数含义\n\n>控制单个Binlog日志大小，一旦达到该参数的限制，会产生新的binlog文件（一个binlog文件最大 1G）\n\n#### 取值范围\n\n>4096--1073741824\n\n#### 推荐值\n\n>512M\n\n#### 注意\n\n### 7、innodb_log_file_size\n\n#### 参数含义\n\n>该参数控制Innodb事务日志文件的大小，日志写满后进行日志切换。所有日志的总大小不能超过512GB,即innodb_log_file_size * innodb_log_files_in_group的值不能大于512GB\n\n#### 取值范围\n\n>\n\n#### 推荐值\n\n>512M\n\n#### 注意\n\n\n### 8、innodb_log_files_in_group\n\n#### 参数含义\n\n>控制Innodb事务日志的个数。如果设置的太小，遭遇事务高峰期，会产生大量的事务日志，频繁发生日志切换。当日志1写满需要切换日志2时，如果日志2中事务对应的脏数据未完成落盘，日志切换只能等待，严重影响mysql的性能。\n\n#### 取值范围\n\n>2-100\n\n#### 推荐值\n\n>2\n\n#### 注意\n\n\n### 9、relay_log_info_repository\n\n#### 参数含义\n\n>控制从库的重做信息以何种方式保存。设置为file，sql线程先提交事务，再记录relay.info文件。假如在relay.info刷盘那一刻宕机，relay.info文件中没有记录，那么从库重启mysql进程后们就会执行两边同样的sql，导致同步复制报错。设置为table，sql线程执行完事务后，立即更新slave_relay_log_info表，如果在更新过程中宕机，则事务会回滚，slave_relay_log_info表并不会记录同步的点，下次重新同步时，从之前的pos点再次执行。\n\n#### 取值范围\n\n>table|file\n\n#### 推荐值\n\n>table\n\n#### 注意\n\n### 10、relay_log_recovery\n\n#### 参数含义\n\n>Slave宕机重启后，对relay-log的处理方式。当slave宕机后，假如relay_log损坏，导致一部分中继日志没有处理，则自动放弃所有未执行的relay-log，并且重新从MASTER上索取日志，保证relay的完整性。默认情况下该功能是关闭的。建议在从库上开启次功能\n\n#### 取值范围\n\n>ON | OFF\n\n#### 推荐值\n\n>ON\n\n#### 注意","tags":["MySQL"]},{"title":"MySQL SQL 查询执行流程","url":"/jingjie.github.io/2019/12/05/MySQL SQL 查询执行流程/","content":"\n# MySQL SQL 查询执行流程\n\n## 流程图\nMySQL 大体可分为 server 层与 存储引擎\n![file](https://cdn.learnku.com/uploads/images/201812/06/23047/2erf6BrLCr.png!large)\n\n## 流程解释\n\n#### 1、连接器\n管理连接，权限验证，当一个连接权限验证通过后，即使你使用管理员对这个用户的权限做了修改，对已经通过验证的接连也不会生效。只有新连接才会使用新的权限\n\n### 2、查询缓存\n命中则直接返回结果，缓存以 key=>value 的形式储存，key 为 SQL 语句，value 为查询的结果，查询缓存当出现更新时，当前表的所有缓存将被清空。\n\n**Note：**因查询缓存往往弊大于利 MySQL 8 及以上版本查询缓存已经被抛弃\n\n### 3、分析器\n对 SQL 进程词法语法分析，并验证表与查询的字段是否存在\n\n### 4、优化器\n对 SQL 进行索引选择\n\n### 5、执行器\n执行 SQL 语句，查询存储引擎，返回结果\n\n\n[原文连接](https://time.geekbang.org/column/article/68319)：https://time.geekbang.org/column/article/68319","tags":["MySQL"]},{"title":"Index Modules","url":"/jingjie.github.io/2019/12/05/Index Modules（表属性设置）/","content":"\n版本：7.5\n\n# Index Settings [详情](https://www.elastic.co/guide/en/elasticsearch/reference/7.5/index-modules.html#_static_index_settings)\n\n表的属性设置按是否可更改可分为：\n\n- (static) 静态\n    - 创建后不能更改，它们只能在创建索引时或在关闭的索引上设置。\n\n- (dynamic) 动态\n    - 创建后，可更改，可以使用 [update-index-settings](https://www.elastic.co/guide/en/elasticsearch/reference/7.5/indices-update-settings.html) API 动态的在活动索引上更改它们。\n\n**WARNING：**\n\n更改关闭索引上的静态或动态索引设置可能导致错误的设置，如果不删除和重新创建索引，就无法纠正这些错误。\n\n## 静态属性设置（static index settings）\n\n下面是与任何特定索引模块无关的所有静态索引设置的列表\n\n属性名/参数名 | 中文名 | 值类型 | 默认值 | 说明\n------|-------|-------|-------|------\nindex.number_of_shards | 分片数量 | int | 1 | 分片数量，**默认 1**，些设置只能在创建时设置。它不能在封闭（关闭）索引上更改。每个索引分片数量限制在 1024 个。这个限制是一个安全限制，用于防止由于资源分配而意外创建可能破坏集群稳定的索引，可以通过 export ES_JAVA_OPTS=\"-Des.index.max_number_of_shards=128\" 来修改这个限制\nindex.shard.check_on_startup | 是否检查分片 | bool、checksum  | false | 分片在打开之前是否检查分片是否损坏，当检查到损坏时，它将阻止分片被打开，可选值：<br> false (默认)打开碎片时不检查是否损坏 <br> checksum 只检查物理损坏 <br> true 检查物理和逻辑损坏，相对比较耗CPU与内存。**专家。在大型索引中，检查碎片可能会花费大量时间，不建议开启**。\nindex.codec | 数据储存的压缩算法 | string | LZ4 | 数据存储的压缩算法，默认值为 LZ4，可选择值 best_compression ，比 LZ4 可以获得更好的压缩比(即占据较小的磁盘空间，但存储性能比 LZ4 低)。\nindex.routing_partition_size | 路由分区数 | int | 1 | **默认 1**，只能在创建时设置。这个值必须小于索引，除非 index.number_of_shards 的值也是 1，其路由算法为：(hash(_routing)  +  hash(_id) % index.routing_parttion_size  ) % number_of_shards。如果该值不设置，则路由算法为  hash(_routing) % number_of_shardings，_routing 默认值为 _id。更多 **[详情](https://www.elastic.co/guide/en/elasticsearch/reference/7.5/mapping-routing-field.html#routing-index-partition)**\nindex.load_fixed_bitset_filters_eagerly | | bool | true | 指示缓存的筛选器是否为嵌套查询预加载。(bool)，默认值：true。最重要的一点，过滤器所处理的查询部分不需要计算文档得分。在1.4版本以后，执行嵌套查询时所使用的 bitsets 默认提前加载就好了。这样做可以使查询更快但更耗费内存。可以通过 index.load_fixed_bitset_filters_eagerl 配置项为 false 来禁用提前加载\n\n\n## 动态属性设置（Dynamic index settings）\n\n下面是所有动态索引设置的列表，不与任何特定的索引模块相关联:\n\n属性名/参数名 | 中文名 | 值类型 | 默认值 | 说明\n------|-------|-------|-------|------\nindex.number_of_replicas | 副本 | int | 1 | 每个分片的副本数量，**默认 1**\nindex.auto_expand_replicas | 副本是否自动扩展 | bool、string | false | 副本是否自动扩展，设置为以破折号分隔的下界和上界(例如0-5)，或将all用于上界(例如0-all)。**默认为 false (即禁用)** 。**注意**：自动扩展的副本数量没有考虑任何其他分配规则，比如分片分配感知、过滤或每个节点的分片总数，如果适用的规则阻止分配所有副本，则可能导致集群健康状态变为黄色。\nindex.search.idle.after | | string | 30s (30 秒) | 设置分片多久没有接收过请求，就会被判定为空闲的时间，默认为30秒。\nindex.refresh_interval | 刷新频率 | string | 1s (1秒) | 执行刷新操作的频率，该操作使索引的最近更改对搜索可见， 默认为1秒， 可以设置为-1表示禁用刷新。<br> 如果显示不设置该值，那些在至少${index.search.idle.after}秒之前没有收到过搜索请求的分片，将不会收到后台的刷新请求，一直要等这些分片收到搜索才会收到后台的刷新请求，如果当前搜索涉及到操作空闲状态的分片时，刷新操作会被挂起直到下一次后台的刷新操作（1秒之内），此行为旨在在未执行搜索时自动优化默认情况下的批量索引。如果不希望执行此默认逻辑，应当显示的将刷新时间间隔设置为1秒。\nindex.max_result_window | | int | 10000 | 控制分页搜索总记录数，from + size 的大小不能超过该值，默认为10000。防止占用过高的内存\nindex.max_inner_result_window | | int | 100 | 从from+ size的最大值，用于控制top aggregations（顶部聚合），默认为100。内部命中和顶部命中聚合占用堆内存，并且时间与    from + size 成正比，防止占用过高的内存。\nindex.max_rescore_window | | int | 10000 | 设置索引的 rescore 请求的 window_size 的最大值， 默认为与 index.max_result_window 的值相同，默认值为 10000，防止占用过高的内存。\nindex.max_docvalue_fields_search | | int | 100 | 查询中允许的最多 docvalue_fields 数量，默认为 100。doc_value 字段的查询成本很高，因为它们可能会导致对每个字段和每个文档执行搜索。\nindex.max_script_fields | | int | 32 | 查询中允许的最多 script_fields 的数量， 默认为32。\nindex.max_ngram_diff | | int | 1 | NGramTokenizer 和 NGramTokenFilter 的 min_gram 和 max_gram 之间允许的最大差异值，默认为 1。\nindex.max_shingle_diff | | int | 3 | 对于 ShingleTokenFilter, max_shingle_size 和 min_shingle_size 之间允许的最大差异。默认为 3。\nindex.blocks.read_only | | bool | | 设置为 true 使索引和索引元数据只读，设置为 false 允许写和元数据更改。\nindex.blocks.read_only_allow_delete | | bool | | 控制索引及其元数据在只读状态下，是否允许执行删除，设置 true 表示允许删除，false 不允许\nindex.blocks.read | | bool | | 是否禁用对索引数据的读操作\nindex.blocks.write | | bool | | 是否禁用对索引的数据写操作。设置为 true 可禁用针对索引的数据写操作。与 read_only 不同，此设置不影响元数据。例如，可以用写块(blocks.write)关闭索引，但不能用 read_only 块关闭索引。\nindex.blocks.metadata | | bool | | 是否禁用对索引元数据的读写。设置为true可禁用索引元数据的读写。\nindex.max_refresh_listeners | | | | 索引的每个分片上当刷新索引时最大的可用监听器数量。这些侦听器用于实现 refresh=wait_for。\nindex.analyze.max_token_count | | int | 10000 | 使用_analyze API可以生成的最大词项数， 默认为10000\nindex.highlight.max_analyzed_offset | | int | 10000 | highlight(高亮) 请求可被分析的最大字符数，此设置仅在 highlight 请求针对没有偏移量或 term vector 的索引文本时才会生效， 默认为 1000000。\nindex.max_terms_count | | int | 65536 | 可在 term 查询中使用的最大 term 数，默认值为 65536。\nindex.max_regex_length | | int | 1000 | 可在 Regexp 查询（正则查询）中使用的正则表达式的最大长度。默认为 1000。\nindex.routing.allocation.enable | 控制索引的分片分配 [参考](https://cloud.tencent.com/developer/article/1361266) | all、primaries、new_primaries、none | all | Allocation机制，其主要解决的是如何将索引在ES集群中在哪些节点上分配分片(例如在Node1是创建的主分片，在其他节点上创建复制分片)。举个例子，如果集群中新增加了一个节点，集群的节点由原来的3个变成了4 可选值: <br> all 所有类型的分片都可以重新分配，默认。<br> primaries 只允许分配主分片。<br> new_primaries 只允许分配新创建的主分片 <br> none 所有的分片都不允许分配。\nindex.routing.rebalance.enable | 索引的分片重新平衡机制 [参考](https://www.jianshu.com/p/210465322e18) | all、primaries、replicas、none | all |  all 是可以对所有的分片进行平衡；primaries 表示只能对主分片进行平衡；replicas 表示只能对副本进行平衡；none 表示对任何分片都不能平衡，也就是禁用了平衡功能。该值一般不需要修改\nindex.gc_deletes | | string | 60s (60秒) | 文档删除后（删除后版本号）还可以存活的周期，默认为 60s。\nindex.default_pipeline | | | | 默认管道聚合器，设置此索引的默认接收节点管道（The default ingest node pipeline），如果设置了默认管道但管道不存在，此索引请求将失败。可以使用pipeline参数覆盖默认值，名为“_none”的特殊pipeline不执行摄取管道。\nindex.required_pipeline | | | | 必要管道聚合器，此索引所需的摄取节点管道。如果设置了所需的管道且管道不存在，则索引请求将失败。无法使用管道参数覆盖所需的管道。**不能同时设置默认管道和必需管道**。特殊管道名称_none表示不会运行摄取管道。\n\n## 其它可在 settings 设置的属性\n\n#### Analysis（分词器）\n\n用于定义分析程序、令牌器、令牌过滤器和字符过滤器的设置，使用自定义分词器时，需要在 settings 里面设置\n\n#### [Index shard allocation](https://www.elastic.co/guide/en/elasticsearch/reference/7.5/index-modules-allocation.html)\n\n控制将分片分配到节点的位置、时间和方式。\n\n#### [Mapping](https://www.elastic.co/guide/en/elasticsearch/reference/7.5/index-modules.html#_settings_in_other_index_modules)\n\n为索引启用或禁用动态映射。\n\n#### [Merging](https://www.elastic.co/guide/en/elasticsearch/reference/7.5/index-modules-merge.html)\n\n控制如何通过后台合并进程合并分片。\n\n#### [Similarities](https://www.elastic.co/guide/en/elasticsearch/reference/7.5/index-modules-similarity.html)\n\n配置自定义相似度设置，以自定义搜索结果的评分方式。\n\n#### [Slowlog](https://www.elastic.co/guide/en/elasticsearch/reference/7.5/index-modules-slowlog.html)\n\n控制记录查询和获取请求的速度。\n\n#### [Store](https://www.elastic.co/guide/en/elasticsearch/reference/7.5/index-modules-store.html)\n\n配置用于访问碎片数据的文件系统的类型。\n\n#### [Translog](https://www.elastic.co/guide/en/elasticsearch/reference/7.5/index-modules-translog.html)\n\n控制事务日志和后台刷新操作。\n\n#### [History retention](https://www.elastic.co/guide/en/elasticsearch/reference/7.5/index-modules-history-retention.html)\n\n在索引中保留操作历史的控制。\n\n## X-Pack index settings [最后一行](https://www.elastic.co/guide/en/elasticsearch/reference/7.5/index-modules.html#_settings_in_other_index_modules)","tags":["Elasticsearch"]}]